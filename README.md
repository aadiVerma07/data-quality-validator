#Data Quality Validator

A modular **Python-based Data Quality Validation Framework** designed to ensure accuracy, completeness, and consistency of data before it enters analytical or ETL pipelines.

This project validates datasets (CSV, Excel, Database, or API outputs) against configurable rules and generates detailed quality reports â€” helping data engineers and analysts maintain **trustworthy, clean, and reliable data**.

---

## Features

**Config-Driven Architecture** â€“ Easily define validation rules and datasets in YAML/JSON.  
**Rule-Based Validation** â€“ Supports common checks like nulls, duplicates, data type mismatches, regex patterns, and range limits.  
**Dynamic Reporting** â€“ Generates summary and detailed reports in HTML and CSV format.  
**Logging Framework** â€“ Integrated logging for debugging and audit tracking.  
**Modular Design** â€“ Built with scalable and testable architecture (core, utils, config, reports).  
**CLI or Script Execution** â€“ Run validations via command line or integrate as a library in ETL jobs.  

## Future Enhancements

- Add FastAPI integration for API-based validation triggers  
- Add database connectors (MySQL, PostgreSQL, AlloyDB, etc.)  
- Integrate Kafka for real-time validation  
- Add ML-based anomaly detection module  
- Create scheduling & monitoring dashboard  

## Author

**Aditya Kumar**  
Associate Software Engineer @ Accenture  
ğŸ“ B.Tech in Computer Science (AKTU, 2023)  
ğŸ“ Lucknow, India  

ğŸ“§ [email](mailto:aadikumar.world@gmail.com)  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/adityabkumar/) | [GitHub](https://github.com/aadiVerma07)


â­ **If you found this project useful, please give it a star!**  
Your support encourages more open-source work


